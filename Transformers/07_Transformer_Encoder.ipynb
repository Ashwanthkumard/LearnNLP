{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8a4777",
   "metadata": {},
   "source": [
    "# Transformer Encoder in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bdbd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import convert_to_tensor, string\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, Layer\n",
    "from tensorflow.keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08c092f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(Layer):\n",
    "    def __init__(self, d_ff, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fully_connected_1 = Dense(d_ff) # First fully connected layer\n",
    "        self.fully_connected_2 = Dense(d_model) # Second Fully connected layer\n",
    "        self.activation = ReLu() #Relu activation layer\n",
    "    \n",
    "    def call(self,x):\n",
    "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
    "        x_fc1 = self.fully_connected_1(x)\n",
    "        return self.fully_connected_2(self.activation(x_fc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dd4b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddMormalization(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(),__init__(**kwargs)\n",
    "        self.layer_norm = LayerNormalization() # Later Normalization layer\n",
    "    \n",
    "    def call(self, x, sublayer_x):\n",
    "        add = x + sublayer_x\n",
    "        return self.layer_normalization(add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d917b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = DotProductAttention() #Scaled dot product attention\n",
    "        self.heads = h # Number of attention heads to use\n",
    "        self.d_k = d_k # Dimensionality of the linearly projected queries and keys\n",
    "        self.d_v = d_v # Dimensionality of the linearly projected values\n",
    "        self.W_q = Dense(d_k) # Learned projection matrix for the queries\n",
    "        self.W_k = Dense(d_k) # Learned projection matrix for the keys\n",
    "        self.W_v = Dense(d_v) # Learned projection matrix for the values\n",
    "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
    "            \n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], -1))\n",
    "        return x\n",
    "    \n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        \n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25a3c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer):\n",
    "    def __inti__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super().__init__(self,**kwargs)\n",
    "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    "    \n",
    "    def call(self, x, padding_mask, training):\n",
    "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        \n",
    "        # Add in a dropout layer\n",
    "        multihead_output = self.dropout1(multihead_output, training=training)\n",
    "        \n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output = self.add_norm1(x, multihead_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        \n",
    "        feedforward_output = self.feed_forward(addnorm_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        \n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout2(feedforward_output, training=training) \n",
    "        \n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm2(addnorm_output, feedforward_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2e86768",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbeddingFixedWeights(Layer):\n",
    "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)\n",
    "        pos_embedding_matrix = self.get_position_encoding(seq_length, output_dim)\n",
    "\n",
    "        self.word_embedding_layer = Embedding(\n",
    "                                        input_dim = vocab_size,\n",
    "                                        output_dim = output_dim,\n",
    "                                        weights = [word_embedding_matrix],\n",
    "                                        trainable=False)\n",
    "        self.position_embedding_layer = Embedding(\n",
    "                                        input_dim = seq_length,\n",
    "                                        output_dim = output_dim,\n",
    "                                        weights = [pos_embedding_matrix],\n",
    "                                        trainable=False)\n",
    "    \n",
    "    def get_position_encoding(self, seq_len, d, n=10000):\n",
    "        P = np.zeros((seq_len, d))\n",
    "        for k in range(seq_len):\n",
    "            for i in range(int(d/2)):\n",
    "                denominator = np.power(n,2*i/d)\n",
    "                P[k, 2*i] = np.sin(k/denominator)\n",
    "                P[k, 2*i+1] = np.cos(k/denominator)\n",
    "        return P\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
    "        embedded_words = self.word_embedding_layer(inputs)\n",
    "        embedded_indices = self.position_embedding_layer(position_indices)\n",
    "        return embedded_words + embedded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db68414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.encoder_layer = [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
    "    \n",
    "    def call(self, input_sentence, padding_mask, training):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.encoder_layer):\n",
    "            x = layer(x, padding_mask, training)\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe5d33",
   "metadata": {},
   "source": [
    "### Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6dbd9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 8 # Number of self-attention heads\n",
    "d_k = 64 # Dimensionality of the linearly projected queries and keys \n",
    "d_v = 64 # Dimensionality of the linearly projected values\n",
    "d_ff = 2048 # Dimensionality of the inner fully connected layer \n",
    "d_model = 512 # Dimensionality of the model sub-layers' outputs\n",
    "n = 6 # Number of layers in the encoder stack\n",
    "batch_size = 64 # Batch size from the training process\n",
    "dropout_rate = 0.1 # Frequency of dropping the input units in the dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b72e329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vocab_size = 20 # Vocabulary size for the encoder \n",
    "input_seq_length = 5 # Maximum length of the input sequence\n",
    "input_seq = random.random((batch_size, input_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1748621d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes from 1 to 5 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_vocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoder(input_seq, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[0;34m(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding \u001b[38;5;241m=\u001b[39m PositionEmbeddingFixedWeights(sequence_length, vocab_size,d_model)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m Dropout(rate)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layer \u001b[38;5;241m=\u001b[39m [EncoderLayer(h, d_k, d_v, d_model, d_ff, rate) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)]\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding \u001b[38;5;241m=\u001b[39m PositionEmbeddingFixedWeights(sequence_length, vocab_size,d_model)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m Dropout(rate)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layer \u001b[38;5;241m=\u001b[39m [\u001b[43mEncoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_ff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes from 1 to 5 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(enc_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate) \n",
    "print(encoder(input_seq, None, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd4220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
