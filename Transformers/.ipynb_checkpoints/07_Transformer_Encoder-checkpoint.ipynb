{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8a4777",
   "metadata": {},
   "source": [
    "# Transformer Encoder in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bdbd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import convert_to_tensor, string, matmul, math, cast, float32, reshape, shape, transpose\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, Layer\n",
    "from tensorflow.keras.layers import LayerNormalization, Layer, Dense, ReLU, Dropout\n",
    "from numpy import random\n",
    "from tensorflow.keras.backend import softmax\n",
    "from tensorflow.keras.layers import Input \n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08c092f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(Layer):\n",
    "    def __init__(self, d_ff, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fully_connected_1 = Dense(d_ff) # First fully connected layer\n",
    "        self.fully_connected_2 = Dense(d_model) # Second Fully connected layer\n",
    "        self.activation = ReLU() #Relu activation layer\n",
    "    \n",
    "    def call(self,x):\n",
    "        # The input is passed into the two fully-connected layers, with a ReLU in between\n",
    "        x_fc1 = self.fully_connected_1(x)\n",
    "        return self.fully_connected_2(self.activation(x_fc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f09d1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNormalization(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer_norm = LayerNormalization() # Later Normalization layer\n",
    "    \n",
    "    def call(self, x, sublayer_x):\n",
    "        add = x + sublayer_x\n",
    "        return self.layer_norm(add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d932c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(Layer):\n",
    "    def __int__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self,queries,keys,values,d_k,mask=None):\n",
    "        # Scoring the queries against the keys after transposing the latter, and scaling \n",
    "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None: scores += -1e9 * mask\n",
    "                 # Computing the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "        # Computing the attention by a weighted sum of the value vectors\n",
    "        return matmul(weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "115f8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, h, d_k, d_v, d_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = DotProductAttention() #Scaled dot product attention\n",
    "        self.heads = h # Number of attention heads to use\n",
    "        self.d_k = d_k # Dimensionality of the linearly projected queries and keys\n",
    "        self.d_v = d_v # Dimensionality of the linearly projected values\n",
    "        self.W_q = Dense(d_k) # Learned projection matrix for the queries\n",
    "        self.W_k = Dense(d_k) # Learned projection matrix for the keys\n",
    "        self.W_v = Dense(d_v) # Learned projection matrix for the values\n",
    "        self.W_o = Dense(d_model) # Learned projection matrix for the multi-head output\n",
    "            \n",
    "    def reshape_tensor(self, x, heads, flag):\n",
    "        if flag:\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], heads, -1))\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "        else:\n",
    "            x = transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = reshape(x, shape=(shape(x)[0], shape(x)[1], -1))\n",
    "        return x\n",
    "    \n",
    "    def call(self, queries, keys, values, mask=None):\n",
    "        q_reshaped = self.reshape_tensor(self.W_q(queries), self.heads, True)\n",
    "        k_reshaped = self.reshape_tensor(self.W_k(keys), self.heads, True)\n",
    "        v_reshaped = self.reshape_tensor(self.W_v(values), self.heads, True)\n",
    "        o_reshaped = self.attention(q_reshaped, k_reshaped, v_reshaped, self.d_k, mask)\n",
    "        \n",
    "        output = self.reshape_tensor(o_reshaped, self.heads, False)\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "762ad7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, sequence_length, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.multihead_attention = MultiHeadAttention(h, d_k, d_v, d_model)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.add_norm1 = AddNormalization()\n",
    "        self.feed_forward = FeedForward(d_ff, d_model)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.add_norm2 = AddNormalization()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def call(self, x, padding_mask, training):\n",
    "        multihead_output = self.multihead_attention(x, x, x, padding_mask)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        \n",
    "        # Add in a dropout layer\n",
    "        multihead_output = self.dropout1(multihead_output, training=training)\n",
    "        \n",
    "        # Followed by an Add & Norm layer\n",
    "        addnorm_output = self.add_norm1(x, multihead_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        \n",
    "        feedforward_output = self.feed_forward(addnorm_output)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        \n",
    "        # Add in another dropout layer\n",
    "        feedforward_output = self.dropout2(feedforward_output, training=training) \n",
    "        \n",
    "        # Followed by another Add & Norm layer\n",
    "        return self.add_norm2(addnorm_output, feedforward_output)\n",
    "    \n",
    "    def build_graph(self):\n",
    "        input_layer = Input(shape=(self.sequence_length, self.d_model))\n",
    "        return Model(inputs=[input_layer], outputs=self.call(input_layer, None, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9763e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbeddingFixedWeights(Layer):\n",
    "    def __init__(self, seq_length, vocab_size, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        word_embedding_matrix = self.get_position_encoding(vocab_size, output_dim)\n",
    "        pos_embedding_matrix = self.get_position_encoding(seq_length, output_dim)\n",
    "\n",
    "        self.word_embedding_layer = Embedding(\n",
    "                                        input_dim = vocab_size,\n",
    "                                        output_dim = output_dim,\n",
    "                                        weights = [word_embedding_matrix],\n",
    "                                        trainable=False)\n",
    "        self.position_embedding_layer = Embedding(\n",
    "                                        input_dim = seq_length,\n",
    "                                        output_dim = output_dim,\n",
    "                                        weights = [pos_embedding_matrix],\n",
    "                                        trainable=False)\n",
    "    \n",
    "    def get_position_encoding(self, seq_len, d, n=10000):\n",
    "        P = np.zeros((seq_len, d))\n",
    "        for k in range(seq_len):\n",
    "            for i in range(int(d/2)):\n",
    "                denominator = np.power(n,2*i/d)\n",
    "                P[k, 2*i] = np.sin(k/denominator)\n",
    "                P[k, 2*i+1] = np.cos(k/denominator)\n",
    "        return P\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        position_indices = tf.range(tf.shape(inputs)[-1])\n",
    "        embedded_words = self.word_embedding_layer(inputs)\n",
    "        embedded_indices = self.position_embedding_layer(position_indices)\n",
    "        return embedded_words + embedded_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b5b1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Layer):\n",
    "    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size,d_model)\n",
    "        self.dropout = Dropout(rate)\n",
    "        self.encoder_layer = [EncoderLayer(sequence_length, h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n",
    "    \n",
    "    def call(self, input_sentence, padding_mask, training):\n",
    "        # Generate the positional encoding\n",
    "        pos_encoding_output = self.pos_encoding(input_sentence)\n",
    "        # Expected output shape = (batch_size, sequence_length, d_model)\n",
    "        # Add in a dropout layer\n",
    "        x = self.dropout(pos_encoding_output, training=training)\n",
    "        # Pass on the positional encoded values to each encoder layer\n",
    "        for i, layer in enumerate(self.encoder_layer):\n",
    "            x = layer(x, padding_mask, training)\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f35b5b",
   "metadata": {},
   "source": [
    "### Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd98cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 8 # Number of self-attention heads\n",
    "d_k = 64 # Dimensionality of the linearly projected queries and keys \n",
    "d_v = 64 # Dimensionality of the linearly projected values\n",
    "d_ff = 2048 # Dimensionality of the inner fully connected layer \n",
    "d_model = 512 # Dimensionality of the model sub-layers' outputs\n",
    "n = 6 # Number of layers in the encoder stack\n",
    "batch_size = 64 # Batch size from the training process\n",
    "dropout_rate = 0.1 # Frequency of dropping the input units in the dropout layers\n",
    "enc_seq_length = 5 # Maximum length of the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db8be653",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vocab_size = 20 # Vocabulary size for the encoder \n",
    "input_seq_length = 5 # Maximum length of the input sequence\n",
    "input_seq = random.random((batch_size, input_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b660c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(enc_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate) \n",
    "# print(encoder(input_seq, None, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "885c3f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"multi_head_attention_27\" (type MultiHeadAttention).\n\nin user code:\n\n    File \"<ipython-input-29-3dac0503d0f9>\", line 29, in call  *\n        return self.W_o(output)\n    File \"/Users/a.daggula/opt/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/a.daggula/opt/miniconda3/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 139, in build\n        raise ValueError('The last dimension of the inputs to a Dense layer '\n\n    ValueError: The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, 5, None)\n\n\nCall arguments received:\n  • queries=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • keys=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • values=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder \u001b[38;5;241m=\u001b[39m EncoderLayer(enc_seq_length, h, d_k, d_v, d_model, d_ff, dropout_rate)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mEncoderLayer.build_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_graph\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     34\u001b[0m     input_layer \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model))\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Model(inputs\u001b[38;5;241m=\u001b[39m[input_layer], outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mEncoderLayer.call\u001b[0;34m(self, x, padding_mask, training)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, padding_mask, training):\n\u001b[0;32m---> 14\u001b[0m     multihead_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Expected output shape = (batch_size, sequence_length, d_model)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Add in a dropout layer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     multihead_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(multihead_output, training\u001b[38;5;241m=\u001b[39mtraining)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:699\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    698\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    700\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"multi_head_attention_27\" (type MultiHeadAttention).\n\nin user code:\n\n    File \"<ipython-input-29-3dac0503d0f9>\", line 29, in call  *\n        return self.W_o(output)\n    File \"/Users/a.daggula/opt/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/a.daggula/opt/miniconda3/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 139, in build\n        raise ValueError('The last dimension of the inputs to a Dense layer '\n\n    ValueError: The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, 5, None)\n\n\nCall arguments received:\n  • queries=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • keys=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • values=tf.Tensor(shape=(None, 5, 512), dtype=float32)\n  • mask=None"
     ]
    }
   ],
   "source": [
    "encoder = EncoderLayer(enc_seq_length, h, d_k, d_v, d_model, d_ff, dropout_rate)\n",
    "encoder.build_graph().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde19f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93ea00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
