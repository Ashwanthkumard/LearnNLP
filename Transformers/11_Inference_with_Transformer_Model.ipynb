{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442f9877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. 0. 1. 1. 1.], shape=(7,), dtype=float32)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5, 512)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_42 (Multi  (None, 5, 512)      131776      ['input_1[0][0]',                \n",
      " HeadAttention)                                                   'input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 5, 512)       0           ['multi_head_attention_42[0][0]']\n",
      "                                                                                                  \n",
      " add_normalization_72 (AddNorma  (None, 5, 512)      1024        ['input_1[0][0]',                \n",
      " lization)                                                        'dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      " feed_forward_30 (FeedForward)  (None, 5, 512)       2099712     ['add_normalization_72[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 5, 512)       0           ['feed_forward_30[0][0]']        \n",
      "                                                                                                  \n",
      " add_normalization_73 (AddNorma  (None, 5, 512)      1024        ['add_normalization_72[0][0]',   \n",
      " lization)                                                        'dropout_78[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,233,536\n",
      "Trainable params: 2,233,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 5, 512)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_43 (Multi  (None, 5, 512)      131776      ['input_2[0][0]',                \n",
      " HeadAttention)                                                   'input_2[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 5, 512)       0           ['multi_head_attention_43[0][0]']\n",
      "                                                                                                  \n",
      " add_normalization_74 (AddNorma  (None, 5, 512)      1024        ['input_2[0][0]',                \n",
      " lization)                                                        'dropout_79[0][0]',             \n",
      "                                                                  'add_normalization_74[0][0]',   \n",
      "                                                                  'dropout_80[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_44 (Multi  (None, 5, 512)      131776      ['add_normalization_74[0][0]',   \n",
      " HeadAttention)                                                   'input_2[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 5, 512)       0           ['multi_head_attention_44[0][0]']\n",
      "                                                                                                  \n",
      " feed_forward_31 (FeedForward)  (None, 5, 512)       2099712     ['add_normalization_74[1][0]']   \n",
      "                                                                                                  \n",
      " dropout_81 (Dropout)           (None, 5, 512)       0           ['feed_forward_31[0][0]']        \n",
      "                                                                                                  \n",
      " add_normalization_76 (AddNorma  (None, 5, 512)      1024        ['add_normalization_74[1][0]',   \n",
      " lization)                                                        'dropout_81[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,365,312\n",
      "Trainable params: 2,365,312\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "<START>i like french<EOS> \n",
      " tf.Tensor([  1   3  31 306   2], shape=(5,), dtype=int64)\n",
      "<START>die sind zu hause<EOS> \n",
      " tf.Tensor([ 1 23 20 19 69  2  0  0  0  0], shape=(10,), dtype=int64)\n",
      "Encoder sequence length: 5\n",
      "Decoder sequence length: 10\n",
      "\n",
      "Start of epoch 1\n",
      "Epoch 1 Step 0 Loss 8.3297 Accuracy 0.0000\n",
      "Epoch 1 Step 50 Loss 7.4354 Accuracy 0.1308\n",
      "Epoch 1 Step 100 Loss 6.6282 Accuracy 0.1659\n",
      "Epoch 1: Training Loss 6.1647, Training Accuracy 0.1803\n",
      "\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0 Loss 4.7449 Accuracy 0.2172\n",
      "Epoch 2 Step 50 Loss 4.3305 Accuracy 0.1751\n",
      "Epoch 2 Step 100 Loss 4.0125 Accuracy 0.1457\n",
      "Epoch 2: Training Loss 3.7926, Training Accuracy 0.1335\n"
     ]
    }
   ],
   "source": [
    "%run 10_Train_Transformers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb78242d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define the dataset parameters\n",
    "enc_seq_length = 7 # Encoder sequence length \n",
    "dec_seq_length = 12 # Decoder sequence length \n",
    "enc_vocab_size = 2405 # Encoder vocabulary size \n",
    "dec_vocab_size = 3858 # Decoder vocabulary size\n",
    " # Create model\n",
    "inferencing_model = TransformerModel(enc_vocab_size, dec_vocab_size, enc_seq_length,\n",
    "                                      dec_seq_length, h, d_k, d_v, d_model, d_ff, n, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f926ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from tensorflow import Module\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import convert_to_tensor, int64, TensorArray, argmax, newaxis, transpose \n",
    "\n",
    "   \n",
    "class Translate(Module):\n",
    "    def __init__(self, inferencing_model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.transformer = inferencing_model\n",
    "\n",
    "    def load_tokenizer(self, name):\n",
    "        with open(name, 'rb') as handle:\n",
    "            return load(handle)\n",
    "        \n",
    "    def __call__(self, sentence):\n",
    "        # Append start and end of string tokens to the input sentence \n",
    "        sentence[0] = \"<START> \" + sentence[0] + \" <EOS>\"\n",
    "        # Load encoder and decoder tokenizers\n",
    "        enc_tokenizer = self.load_tokenizer('enc_tokenizer.pkl')\n",
    "        dec_tokenizer = self.load_tokenizer('dec_tokenizer.pkl')\n",
    "        # Prepare the input sentence by tokenizing, padding and converting to tensor\n",
    "        encoder_input = enc_tokenizer.texts_to_sequences(sentence)\n",
    "        encoder_input = pad_sequences(encoder_input,\n",
    "                                      maxlen=enc_seq_length, padding='post')\n",
    "        encoder_input = convert_to_tensor(encoder_input, dtype=int64)\n",
    "        \n",
    "        # Prepare the output <START> token by tokenizing, and converting to tensor\n",
    "        output_start = dec_tokenizer.texts_to_sequences([\"<START>\"])\n",
    "        output_start = convert_to_tensor(output_start[0], dtype=int64)\n",
    "        \n",
    "        # Prepare the output <EOS> token by tokenizing, and converting to tensor\n",
    "        output_end = dec_tokenizer.texts_to_sequences([\"<EOS>\"])\n",
    "        output_end = convert_to_tensor(output_end[0], dtype=int64)\n",
    "        \n",
    "        # Prepare the output array of dynamic size\n",
    "        decoder_output = TensorArray(dtype=int64, size=0, dynamic_size=True) \n",
    "        decoder_output = decoder_output.write(0, output_start)\n",
    "        \n",
    "        for i in range(dec_seq_length):\n",
    "            # Predict an output token\n",
    "            prediction = self.transformer(encoder_input,transpose(decoder_output.stack()),training=False) \n",
    "            prediction = prediction[:, -1, :]\n",
    "            \n",
    "            # Select the prediction with the highest score\n",
    "            predicted_id = argmax(prediction, axis=-1)\n",
    "            predicted_id = predicted_id[0][newaxis]\n",
    "        \n",
    "            # Write the selected prediction to the output array at the next \n",
    "            # available index\n",
    "            decoder_output = decoder_output.write(i + 1, predicted_id)\n",
    "            # Break if an <EOS> token is predicted\n",
    "            if predicted_id == output_end: \n",
    "                break\n",
    "        output = transpose(decoder_output.stack())[0]\n",
    "\n",
    "        output = output.numpy()\n",
    "        output_str = []\n",
    "        # Decode the predicted tokens into an output string\n",
    "        for i in range(output.shape[0]): \n",
    "            key = output[i]\n",
    "            output_str.append(dec_tokenizer.index_word[key]) \n",
    "        return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dac8a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['im thirsty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ecc0799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferencing_model.load_weights('weights/wghts16.ckpt')\n",
    "translator = Translate(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18f5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(translator(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285377a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
